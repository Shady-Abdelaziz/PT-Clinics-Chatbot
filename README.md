# üè• Medical Center AI Chatbot

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Status](https://img.shields.io/badge/status-production%20ready-success.svg)

**A Production-Ready, Privacy-Focused AI-Powered Medical Assistant**

[Features](#-features) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [Configuration](#-configuration) ‚Ä¢ [API Reference](#-api-reference)

</div>

---

## üìã Table of Contents

- [Overview](#-overview)
- [Key Features](#-features)
- [System Architecture](#-architecture)
- [Technology Stack](#-technology-stack)
- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Project Structure](#-project-structure)
- [Development](#-development)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Security](#-security)
- [Performance](#-performance)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## üéØ Overview

The **Medical Center AI Chatbot** is an enterprise-grade, intelligent conversational assistant designed specifically for healthcare facilities. It combines the power of Large Language Models (LLMs) with specialized medical domain knowledge to provide accurate, HIPAA-conscious patient support.

### What Makes It Different?

- **üîí Privacy-First**: Optional local LLM processing with Ollama (no data leaves your infrastructure)
- **üéØ Domain-Specific**: Trained on medical center policies, doctor information, and healthcare workflows
- **‚ö° Real-Time**: Instant appointment booking, cancellation, and availability checks
- **üìä Data Integration**: Direct integration with Excel-based appointment databases
- **üß† Context-Aware**: Maintains conversation history for natural, flowing interactions
- **üöÄ Production-Ready**: Built with Flask, includes error handling, logging, and monitoring hooks

### Use Cases

- **Patient Support**: Answer questions about doctors, specialties, and services
- **Appointment Management**: Book, cancel, and search appointments in real-time
- **Information Retrieval**: Quick access to medical center policies and procedures
- **24/7 Availability**: Automated responses to common queries
- **Load Reduction**: Reduce call center volume by 30-50%

---

## ‚ú® Features

### Core Capabilities

#### ü§ñ Intelligent Conversation
- Natural language understanding powered by advanced LLMs
- Context-aware responses with conversation memory (10-message window)
- Multi-turn dialogue support
- Intent classification and entity extraction

#### üìÖ Appointment Management
- **Check Availability**: Real-time doctor schedule queries
- **Book Appointments**: Instant reservation with validation
- **Cancel Appointments**: Easy cancellation with confirmation
- **Search Appointments**: Find existing appointments by patient or doctor
- **Smart Scheduling**: Conflict detection and prevention

#### üîç Knowledge Base
- Semantic search across medical documents
- Doctor profiles (specialties, experience, education, contact)
- Physical therapy information and procedures
- Operating hours and contact information
- Medical center policies and guidelines

#### üìä Database Integration
- Excel-based appointment database with color-coded status
- Real-time read/write operations
- Data validation and integrity checks
- Automatic backup recommendations

### Technical Features

#### üèóÔ∏è Architecture
- **Modular Design**: Separation of concerns (agents, tools, utilities)
- **Scalable**: Handles concurrent users with session management
- **Extensible**: Easy to add new agents, tools, or data sources
- **RESTful API**: Clean HTTP endpoints for all operations

#### üîê Security & Privacy
- Optional local LLM processing (Ollama)
- No PHI (Protected Health Information) sent to external APIs when using Ollama
- Session-based conversation tracking
- Environment-based configuration
- API key protection

#### ‚ö° Performance
- Response time: 2-5 seconds for information queries
- Vector database for sub-second semantic search
- Efficient embedding generation with batching
- Connection pooling and timeout management

---

## üèóÔ∏è Architecture

### High-Level System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         User Interface Layer                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Web Browser (HTML/CSS/JavaScript)                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Modern gradient UI                                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Real-time chat interface                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Responsive design                                            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ HTTP/REST API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                               ‚ñº                                       ‚îÇ
‚îÇ                     Application Layer (Flask)                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  API Endpoints                                                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ POST /api/chat      - Process user messages                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GET  /api/history   - Retrieve conversation history         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ POST /api/clear     - Clear conversation                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GET  /api/info      - Get medical center info               ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                               ‚îÇ                                       ‚îÇ
‚îÇ                               ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Session Management                                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ UUID-based session tracking                                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ In-memory conversation storage                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Context maintenance (10-message window)                      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                               ‚ñº                                        ‚îÇ
‚îÇ                    AI Agent Layer (CrewAI)                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Medical Chatbot (Orchestrator)                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Query analysis and routing                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Function call extraction and execution                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Response generation and formatting                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Conversation memory management                               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                        ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ
‚îÇ                    ‚ñº          ‚ñº          ‚ñº                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ Information  ‚îÇ ‚îÇ  Appointment  ‚îÇ ‚îÇ  Knowledge       ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ   Tools      ‚îÇ ‚îÇ    Tools      ‚îÇ ‚îÇ  Search Tools    ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                               ‚ñº                                        ‚îÇ
‚îÇ                      Integration Layer                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  LLM Integration (OpenRouter)                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Model: tngtech/deepseek-r1t2-chimera:free               ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Text generation                                        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Function call detection                                ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Response formatting                                    ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Embedding Service (Ollama - Local)                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Model: nomic-embed-text:latest                          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Document embedding generation                          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Query embedding for semantic search                    ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚Ä¢ Vector dimension: 768                                  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                               ‚ñº                                        ‚îÇ
‚îÇ                        Data Layer                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Vector Database (Qdrant Cloud)                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Collection: medical_center_knowledge                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Distance metric: Cosine similarity                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Stores: Doctor info, PT procedures, policies                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Features: Semantic search, relevance scoring                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Excel Database (Local File)                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ File: Simple_Clinic_Database.xlsx                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Sheets: One per doctor                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Columns: Date, Time, Patient_Name, Phone, Status            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Color coding: Green (booked), White (available)             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                               ‚îÇ                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Knowledge Base (PDF Documents)                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Doctor_Information_Guide.pdf                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Physical_Therapy_Clinic_Guide.pdf                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Indexed and chunked for semantic search                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    User     ‚îÇ
‚îÇ   Query     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îÇ 1. HTTP POST /api/chat
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Flask Application                   ‚îÇ
‚îÇ  ‚Ä¢ Session management                       ‚îÇ
‚îÇ  ‚Ä¢ Request validation                       ‚îÇ
‚îÇ  ‚Ä¢ Context loading                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îÇ 2. Query + Context
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Medical Chatbot                        ‚îÇ
‚îÇ  ‚Ä¢ Conversation memory                      ‚îÇ
‚îÇ  ‚Ä¢ System prompt injection                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îÇ 3. Messages array
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      OpenRouter LLM                         ‚îÇ
‚îÇ  ‚Ä¢ DeepSeek-R1T2-Chimera                    ‚îÇ
‚îÇ  ‚Ä¢ Temperature: 0.1                         ‚îÇ
‚îÇ  ‚Ä¢ Max tokens: 4080                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îÇ 4. Response with function call
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Function Call Extraction                  ‚îÇ
‚îÇ  ‚Ä¢ XML/text pattern matching                ‚îÇ
‚îÇ  ‚Ä¢ Argument parsing                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ             ‚îÇ              ‚îÇ              ‚îÇ
       ‚ñº             ‚ñº              ‚ñº              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Knowledge  ‚îÇ ‚îÇ  Excel   ‚îÇ ‚îÇ  Doctor   ‚îÇ ‚îÇ Appointment ‚îÇ
‚îÇ  Search    ‚îÇ ‚îÇ Manager  ‚îÇ ‚îÇ   List    ‚îÇ ‚îÇ   Search    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ             ‚îÇ              ‚îÇ               ‚îÇ
      ‚ñº             ‚ñº              ‚ñº               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Qdrant  ‚îÇ ‚îÇ     Excel Database Operations          ‚îÇ
‚îÇ  Vector  ‚îÇ ‚îÇ  ‚Ä¢ Read schedules                      ‚îÇ
‚îÇ    DB    ‚îÇ ‚îÇ  ‚Ä¢ Book appointments                   ‚îÇ
‚îÇ          ‚îÇ ‚îÇ  ‚Ä¢ Cancel appointments                 ‚îÇ
‚îÇ          ‚îÇ ‚îÇ  ‚Ä¢ Search appointments                 ‚îÇ
‚îÇ          ‚îÇ ‚îÇ  ‚Ä¢ Check availability                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ             ‚îÇ
     ‚îÇ 5. Function results
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                        ‚îÇ
                                        ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ  Result Formatting            ‚îÇ
                        ‚îÇ  ‚Ä¢ Second LLM call            ‚îÇ
                        ‚îÇ  ‚Ä¢ Context-aware response     ‚îÇ
                        ‚îÇ  ‚Ä¢ Natural language output    ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚îÇ 6. Formatted response
                                ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ  Flask Response               ‚îÇ
                        ‚îÇ  ‚Ä¢ JSON formatting            ‚îÇ
                        ‚îÇ  ‚Ä¢ Session update             ‚îÇ
                        ‚îÇ  ‚Ä¢ Memory storage             ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚îÇ 7. HTTP 200 + JSON
                                ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ   User Interface              ‚îÇ
                        ‚îÇ   ‚Ä¢ Display response          ‚îÇ
                        ‚îÇ   ‚Ä¢ Update chat history       ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Interaction Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Medical Chatbot Flow                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

User Query: "Who is Dr. Sarah Martinez?"
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. ANALYZE QUERY                                                    ‚îÇ
‚îÇ    System: Load conversation history (10 messages)                  ‚îÇ
‚îÇ    System: Inject system prompt with:                               ‚îÇ
‚îÇ            - Available functions                                    ‚îÇ
‚îÇ            - Medical center info                                    ‚îÇ
‚îÇ            - Conversation rules                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. LLM PROCESSING                                                   ‚îÇ
‚îÇ    OpenRouter: Process query with context                           ‚îÇ
‚îÇ    Decision: This requires knowledge search                         ‚îÇ
‚îÇ    Output: "search_knowledge: Dr. Sarah Martinez"                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. FUNCTION EXTRACTION                                              ‚îÇ
‚îÇ    Parser: Extract function name: "search_knowledge"                ‚îÇ
‚îÇ    Parser: Extract arguments: "Dr. Sarah Martinez"                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. FUNCTION EXECUTION                                               ‚îÇ
‚îÇ    VectorDB: Generate query embedding (Ollama)                      ‚îÇ
‚îÇ    VectorDB: Search Qdrant with cosine similarity                   ‚îÇ
‚îÇ    VectorDB: Filter by score threshold (0.1)                        ‚îÇ
‚îÇ    VectorDB: Return top 10 results                                  ‚îÇ
‚îÇ    Result: "Dr. Sarah Martinez - Specializes in..."                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. RESPONSE FORMATTING                                              ‚îÇ
‚îÇ    System: Create new LLM call with:                                ‚îÇ
‚îÇ            - Original query                                         ‚îÇ
‚îÇ            - Function result                                        ‚îÇ
‚îÇ            - Conversation context                                   ‚îÇ
‚îÇ    OpenRouter: Generate natural language response                   ‚îÇ
‚îÇ    Output: "Dr. Sarah Martinez is a Cardiology specialist..."       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. MEMORY UPDATE                                                    ‚îÇ
‚îÇ    Memory: Add user message to history                              ‚îÇ
‚îÇ    Memory: Add AI response to history                               ‚îÇ
‚îÇ    Memory: Trim to 10 messages if needed                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
     Response returned to user
```

### Database Schema

#### Excel Appointment Database

```
File: Simple_Clinic_Database.xlsx

Sheet Structure (One sheet per doctor):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Date         ‚îÇ Time     ‚îÇ Patient_Name ‚îÇ Phone        ‚îÇ Status     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2025-11-19   ‚îÇ 09:00 AM ‚îÇ John Doe     ‚îÇ 555-0100     ‚îÇ Booked     ‚îÇ
‚îÇ 2025-11-19   ‚îÇ 09:30 AM ‚îÇ [Empty]      ‚îÇ [Empty]      ‚îÇ Available  ‚îÇ
‚îÇ 2025-11-19   ‚îÇ 10:00 AM ‚îÇ [Empty]      ‚îÇ [Empty]      ‚îÇ Available  ‚îÇ
‚îÇ 2025-11-19   ‚îÇ 10:30 AM ‚îÇ Jane Smith   ‚îÇ 555-0200     ‚îÇ Booked     ‚îÇ
‚îÇ ...          ‚îÇ ...      ‚îÇ ...          ‚îÇ ...          ‚îÇ ...        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Color Coding:
‚Ä¢ Green cells = Booked appointments
‚Ä¢ White cells = Available slots
‚Ä¢ Date format: YYYY-MM-DD
‚Ä¢ Time format: HH:MM AM/PM
```

#### Qdrant Vector Database

```
Collection: medical_center_knowledge

Vector Configuration:
‚Ä¢ Dimension: 768 (nomic-embed-text)
‚Ä¢ Distance: Cosine
‚Ä¢ Index: HNSW (Hierarchical Navigable Small World)

Document Structure:
{
  "id": "uuid-string",
  "vector": [0.123, -0.456, ...],  // 768 dimensions
  "payload": {
    "text": "Dr. Sarah Martinez specializes in...",
    "metadata": {
      "filename": "Doctor_Information_Guide.pdf",
      "source_type": "pdf",
      "chunk_index": 0,
      "total_chunks": 45
    }
  }
}
```

---

## üíª Technology Stack

### Backend Framework
- **Flask 3.0.0** - Lightweight WSGI web application framework
- **Flask-CORS 4.0.0** - Cross-Origin Resource Sharing support

### AI/ML Components
- **OpenRouter API** - LLM provider (DeepSeek-R1T2-Chimera)
- **Ollama** - Local embedding generation (nomic-embed-text)
- **CrewAI 1.4.1** - Multi-agent orchestration framework
- **LangChain 0.3.0** - LLM application framework

### Vector Database
- **Qdrant Client 1.11.3** - Vector similarity search engine
- **Qdrant Cloud** - Managed vector database service

### Data Processing
- **Pandas 2.2.0** - Data manipulation and analysis
- **OpenPyXL 3.1.5** - Excel file operations
- **PyPDF2 3.0.1** - PDF document processing

### Utilities
- **python-dotenv 1.2.1** - Environment variable management
- **Requests 2.32.3** - HTTP library
- **Pydantic 2.12.0** - Data validation using Python type hints

### Development Tools
- **LiteLLM 1.40.0+** - LLM API abstraction layer
- **BeautifulSoup4 4.13.4+** - HTML/XML parsing

---

## üìã Prerequisites

### System Requirements

- **Operating System**: Windows 10/11, macOS 10.15+, or Linux (Ubuntu 20.04+)
- **Python**: Version 3.8 or higher
- **RAM**: Minimum 8GB (16GB recommended for Ollama)
- **Disk Space**: 10GB+ for models and data
- **Network**: Internet connection for OpenRouter API and Qdrant Cloud

### Required Accounts

1. **OpenRouter Account** (Free tier available)
   - Sign up at: https://openrouter.ai/
   - Generate API key from dashboard
   - Free tier: 10 requests/minute

2. **Qdrant Cloud Account** (Free tier available)
   - Sign up at: https://cloud.qdrant.io/
   - Create cluster (free tier: 1GB storage)
   - Get cluster URL and API key

3. **Ollama Installation** (Free, local)
   - Download from: https://ollama.com/
   - Available for Windows, macOS, Linux
   - No account required

### Optional Requirements

- **GPU**: NVIDIA GPU with CUDA support (for faster Ollama processing)
- **Docker**: For containerized deployment
- **Git**: For version control

---

## üöÄ Installation

### Step 1: Clone Repository

```bash
git clone https://github.com/yourusername/medical-center-chatbot.git
cd medical-center-chatbot
```

### Step 2: Create Virtual Environment

**Windows:**
```powershell
python -m venv venv
.\venv\Scripts\activate
```

**macOS/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Install Ollama

**Windows:**
1. Download installer from https://ollama.com/download
2. Run installer and follow instructions
3. Ollama will start automatically

**macOS:**
```bash
brew install ollama
ollama serve
```

**Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Step 5: Download AI Models

```bash
# Open new terminal and run:
ollama pull nomic-embed-text
```

### Step 6: Configure Environment

1. Copy the example environment file:
```bash
cp .env.example .env
```

2. Edit `.env` and add your credentials:
```env
# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
LLM_MODEL=tngtech/deepseek-r1t2-chimera:free

# Qdrant Configuration
QDRANT_URL=your_qdrant_cluster_url_here
QDRANT_API_KEY=your_qdrant_api_key_here
COLLECTION_NAME=medical_center_knowledge

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text:latest
```

### Step 7: Prepare Data

Place your documents in the `data/` directory:
```
data/
‚îú‚îÄ‚îÄ Doctor_Information_Guide.pdf
‚îú‚îÄ‚îÄ Physical_Therapy_Clinic_Guide.pdf
‚îî‚îÄ‚îÄ Simple_Clinic_Database.xlsx
```

### Step 8: Index Documents

```bash
python index_documents.py
```

Expected output:
```
‚úÖ Created collection: medical_center_knowledge
Processing PDF: Doctor_Information_Guide.pdf
‚úÖ PDF Doctor_Information_Guide.pdf: Created 45 chunks
Processing PDF: Physical_Therapy_Clinic_Guide.pdf
‚úÖ PDF Physical_Therapy_Clinic_Guide.pdf: Created 32 chunks
Generating embeddings for 77 documents...
‚úÖ Successfully indexed 77 documents from 2 files!
```

### Step 9: Verify Setup

```bash
python verify_setup.py
```

This will check:
- ‚úÖ Python version
- ‚úÖ Required packages
- ‚úÖ Ollama connection
- ‚úÖ Qdrant connection
- ‚úÖ OpenRouter API key
- ‚úÖ Data files
- ‚úÖ Environment variables

### Step 10: Run Application

```bash
python app.py
```

The application will start on `http://localhost:5000`

---

## ‚öôÔ∏è Configuration

### Environment Variables Reference

#### LLM Configuration
```env
# OpenRouter API
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxx
LLM_MODEL=tngtech/deepseek-r1t2-chimera:free
LLM_TEMPERATURE=0.1                    # 0.0-1.0 (lower = more focused)
LLM_THINKING_ENABLED=false             # Enable reasoning mode
```

#### Embedding Configuration
```env
# Ollama (Local)
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text:latest
```

#### Vector Database
```env
# Qdrant Cloud
QDRANT_URL=https://your-cluster.cloud.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_api_key
COLLECTION_NAME=medical_center_knowledge
QDRANT_TIMEOUT=300                     # Seconds
```

#### Data Files
```env
# Excel Database
EXCEL_DB_PATH=data/Simple_Clinic_Database.xlsx
```

#### Medical Center Information
```env
CENTER_NAME=Medical Center
CENTER_PHONE=(555) 200-1000
PT_PHONE=(555) 200-2000
PT_EMAIL=pt@medicalcenter.com
CENTER_LOCATION=Cairo, Egypt
WEEKDAY_HOURS=Monday-Friday: 7:00 AM - 7:00 PM
SATURDAY_HOURS=Saturday: 8:00 AM - 2:00 PM
SUNDAY_HOURS=Sunday: Closed
```

#### Retrieval Settings
```env
RAG_RETRIEVAL_K=10                     # Number of documents to retrieve
RAG_SCORE_THRESHOLD=0.1                # Minimum relevance score (0.0-1.0)
```

#### Application Settings
```env
# Flask
FLASK_HOST=0.0.0.0
FLASK_PORT=5000
FLASK_DEBUG=True                       # Set to False in production

# Appointments
APPOINTMENT_DURATION=30                # Minutes
MAX_ADVANCE_BOOKING_DAYS=30
CANCELLATION_NOTICE_HOURS=24

# CrewAI
CREW_VERBOSE=False                     # Enable for debugging
MAX_ITERATIONS=10
CREWAI_TRACING_ENABLED=false
```

### Model Selection Guide

#### LLM Models (OpenRouter)

| Model | Cost | Speed | Quality | Best For |
|-------|------|-------|---------|----------|
| `tngtech/deepseek-r1t2-chimera:free` | Free | Fast | Good | Development, testing |
| `anthropic/claude-3-sonnet` | Paid | Medium | Excellent | Production |
| `openai/gpt-4-turbo` | Paid | Medium | Excellent | High-accuracy needs |
| `google/gemini-pro` | Free tier | Fast | Very Good | Balanced use |

#### Embedding Models (Ollama)

| Model | Size | Dimension | Performance | Best For |
|-------|------|-----------|-------------|----------|
| `nomic-embed-text` | 274MB | 768 | Fast | General purpose (recommended) |
| `all-minilm` | 46MB | 384 | Very Fast | Limited resources |
| `mxbai-embed-large` | 670MB | 1024 | Slower | High accuracy |

---

## üìñ Usage

### Starting the Application

1. **Ensure Ollama is running:**
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags
```

2. **Start the Flask server:**
```bash
python app.py
```

3. **Open your browser:**
```
http://localhost:5000
```

### Example Conversations

#### Information Query
```
User: Who is Dr. Sarah Martinez?

Bot: Dr. Sarah Martinez is a board-certified Cardiologist with over 15 years 
of experience. She specializes in preventive cardiology and heart disease 
management. She completed her MD at Cairo University and her cardiology 
fellowship at Mayo Clinic.

üìÖ Availability: Monday-Friday, 8:00 AM - 4:00 PM
üìç Office: Room 203
üìû Phone: (555) 200-1003
```

#### Booking Appointment
```
User: I want to book an appointment with Dr. Sarah Martinez

Bot: I'd be happy to help! Let me check Dr. Martinez's availability.

[Shows available slots for the next 2 weeks]

User: Book for November 20th at 10:00 AM. Patient name is John Doe, 
phone 555-123-4567

Bot: ‚úÖ Appointment booked successfully!

üìã Appointment Details:
üë®‚Äç‚öïÔ∏è Doctor: Dr. Sarah Martinez
üìÖ Date: November 20, 2025
‚è∞ Time: 10:00 AM
üë§ Patient: John Doe
üìû Phone: 555-123-4567

You will receive a confirmation call 24 hours before your appointment.
```

#### Checking Availability
```
User: What times are available with Dr. Martinez next week?

Bot: Here are Dr. Martinez's available slots for next week:

üìÖ November 22, 2025 (Monday):
   ‚Ä¢ 9:00 AM
   ‚Ä¢ 11:30 AM
   ‚Ä¢ 2:00 PM

üìÖ November 23, 2025 (Tuesday):
   ‚Ä¢ 8:30 AM
   ‚Ä¢ 10:00 AM
   ‚Ä¢ 3:30 PM

üìÖ November 24, 2025 (Wednesday):
   ‚Ä¢ 9:30 AM
   ‚Ä¢ 1:00 PM

Total: 8 available slots

Would you like to book one of these times?
```

#### Canceling Appointment
```
User: I need to cancel John Doe's appointment with Dr. Martinez on November 20th

Bot: I found your appointment:

üë®‚Äç‚öïÔ∏è Doctor: Dr. Sarah Martinez
üìÖ Date: November 20, 2025  
‚è∞ Time: 10:00 AM
üë§ Patient: John Doe

Would you like me to cancel this appointment?

User: Yes, please cancel it

Bot: ‚úÖ Appointment cancelled successfully!

The slot is now available for other patients. Please note our 24-hour 
cancellation policy for future bookings.
```

#### Physical Therapy Inquiry
```
User: Tell me about physical therapy services

Bot: Our Physical Therapy Department offers comprehensive rehabilitation 
services including:

üèÉ‚Äç‚ôÇÔ∏è **Sports Rehabilitation**
- Post-injury recovery
- Strength and conditioning
- Performance optimization

ü¶¥ **Orthopedic Therapy**
- Joint pain management
- Post-surgical rehabilitation
- Mobility improvement

üíÜ‚Äç‚ôÄÔ∏è **Manual Therapy**
- Hands-on treatment techniques
- Soft tissue mobilization
- Joint manipulation

üìç Location: Building B, 2nd Floor
üìû Phone: (555) 200-2000
üìß Email: pt@medicalcenter.com
‚è∞ Hours: Monday-Saturday, 7:00 AM - 7:00 PM

Would you like to book a consultation with our PT team?
```

---

## üìö API Documentation

### REST API Endpoints

#### POST /api/chat
Process a user message and return AI response.

**Request:**
```json
{
  "message": "Who is Dr. Sarah Martinez?"
}
```

**Response:**
```json
{
  "response": "Dr. Sarah Martinez is a board-certified Cardiologist...",
  "session_id": "uuid-string",
  "timestamp": "2025-11-19T10:30:00"
}
```

**Status Codes:**
- `200 OK` - Success
- `400 Bad Request` - Empty message
- `500 Internal Server Error` - Processing error

---

#### GET /api/history
Retrieve conversation history for current session.

**Response:**
```json
{
  "history": [
    {
      "role": "user",
      "content": "Who is Dr. Sarah Martinez?",
      "timestamp": "2025-11-19T10:30:00"
    },
    {
      "role": "assistant",
      "content": "Dr. Sarah Martinez is...",
      "timestamp": "2025-11-19T10:30:05"
    }
  ],
  "session_id": "uuid-string"
}
```

---

#### POST /api/clear
Clear conversation history for current session.

**Response:**
```json
{
  "message": "Conversation cleared"
}
```

---

#### GET /api/info
Get medical center information.

**Response:**
```json
{
  "center_name": "Medical Center",
  "phone": "(555) 200-1000",
  "pt_phone": "(555) 200-2000",
  "pt_email": "pt@medicalcenter.com",
  "location": "Cairo, Egypt",
  "hours": {
    "weekday": "Monday-Friday: 7:00 AM - 7:00 PM",
    "saturday": "Saturday: 8:00 AM - 2:00 PM",
    "sunday": "Sunday: Closed"
  }
}
```

---

## üìÅ Project Structure

```
medical-center-chatbot/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                      # This file - comprehensive documentation
‚îú‚îÄ‚îÄ üìÑ QUICKSTART.md                  # Quick setup guide
‚îú‚îÄ‚îÄ üìÑ PROJECT_SUMMARY.md             # Project overview
‚îú‚îÄ‚îÄ üìÑ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ üìÑ .env                          # Environment configuration (create from .env.example)
‚îú‚îÄ‚îÄ üìÑ .env.example                  # Example environment file
‚îú‚îÄ‚îÄ üìÑ .gitignore                    # Git ignore rules
‚îÇ
‚îú‚îÄ‚îÄ üöÄ app.py                        # Flask web application (main entry point)
‚îú‚îÄ‚îÄ üîß index_documents.py            # Document indexing script
‚îú‚îÄ‚îÄ üß™ verify_setup.py               # Setup verification tool
‚îÇ
‚îú‚îÄ‚îÄ üìÇ src/                          # Source code directory
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ü§ñ agents/                   # AI Agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medical_agents.py        # Chatbot implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crew.py                  # Crew orchestration (legacy)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üî® tools/                    # Agent Tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ medical_tools.py         # Knowledge search, appointments, etc.
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è utils/                    # Utility modules
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py                # Configuration loader
‚îÇ       ‚îú‚îÄ‚îÄ excel_manager.py         # Excel database operations
‚îÇ       ‚îî‚îÄ‚îÄ vector_db_manager.py     # Qdrant + Ollama integration
‚îÇ
‚îú‚îÄ‚îÄ üìÇ templates/                    # HTML templates
‚îÇ   ‚îî‚îÄ‚îÄ index.html                   # Web UI (chat interface)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/                         # Data files
‚îÇ   ‚îú‚îÄ‚îÄ Doctor_Information_Guide.pdf
‚îÇ   ‚îú‚îÄ‚îÄ Physical_Therapy_Clinic_Guide.pdf
‚îÇ   ‚îî‚îÄ‚îÄ Simple_Clinic_Database.xlsx
‚îÇ
‚îî‚îÄ‚îÄ üìÇ docs/                         # Additional documentation (optional)
    ‚îú‚îÄ‚îÄ API.md
    ‚îú‚îÄ‚îÄ DEPLOYMENT.md
    ‚îî‚îÄ‚îÄ CONTRIBUTING.md
```

### Key Files Explained

#### `app.py`
Flask web application that serves the UI and handles API requests. Manages session-based conversation tracking and routes requests to the chatbot.

#### `src/agents/medical_agents.py`
Core chatbot implementation. Handles:
- LLM communication (OpenRouter)
- Function call extraction and execution
- Conversation memory management
- Response generation

#### `src/utils/vector_db_manager.py`
Vector database operations:
- Ollama embedding generation
- Qdrant client management
- Document indexing and chunking
- Semantic search

#### `src/utils/excel_manager.py`
Excel database operations:
- Read appointment schedules
- Book/cancel appointments
- Search and availability checks
- Cell formatting (color coding)

#### `index_documents.py`
One-time setup script to:
- Process PDF documents
- Generate embeddings
- Upload to Qdrant
- Create searchable knowledge base

---

## üõ†Ô∏è Development

### Setting Up Development Environment

1. **Install development dependencies:**
```bash
pip install -r requirements-dev.txt
```

2. **Enable debug mode:**
```env
FLASK_DEBUG=True
CREW_VERBOSE=True
```

3. **Use verbose logging:**
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Adding New Functionality

#### Adding a New Function

1. **Define the function in `src/agents/medical_agents.py`:**
```python
def _execute_function(self, function_name: str, args: str) -> str:
    # ... existing code ...
    
    elif function_name == "my_new_function":
        # Your implementation here
        return result
```

2. **Update system prompt to include the new function:**
```python
system_message = f"""
Available functions:
...
7. To use my new feature:
   my_new_function: arguments
"""
```

3. **Test the new function:**
```python
python
>>> from src.agents import medical_agents
>>> result = medical_agents.handle_query("test my new function")
>>> print(result)
```

#### Adding New Documents

1. **Place files in `data/` directory:**
```bash
cp new_document.pdf data/
```

2. **Re-index documents:**
```bash
python index_documents.py
```

3. **Verify indexing:**
```python
from src.utils import VectorDBManager
manager = VectorDBManager(...)
results = manager.search("test query")
print(results)
```

### Code Style Guidelines

- Follow PEP 8 style guide
- Use type hints for function parameters
- Add docstrings to all classes and functions
- Keep functions small and focused (< 50 lines)
- Use meaningful variable names

### Testing Best Practices

```python
# Example test structure
def test_appointment_booking():
    """Test appointment booking functionality"""
    # Setup
    manager = ExcelDBManager("test_data.xlsx")
    
    # Execute
    success, message = manager.book_appointment(
        doctor_name="Dr. Test",
        date="2025-12-01",
        time="10:00 AM",
        patient_name="Test Patient",
        phone="555-0000"
    )
    
    # Assert
    assert success == True
    assert "successfully" in message.lower()
    
    # Cleanup
    manager.cancel_appointment(
        doctor_name="Dr. Test",
        patient_name="Test Patient"
    )
```

---

## üß™ Testing

### Manual Testing

1. **Test Ollama connection:**
```bash
curl http://localhost:11434/api/tags
```

2. **Test Qdrant connection:**
```bash
curl -X GET "https://your-cluster.cloud.qdrant.io:6333/collections" \
  -H "api-key: your_api_key"
```

3. **Test embedding generation:**
```python
from src.utils.vector_db_manager import OllamaEmbeddings

embeddings = OllamaEmbeddings("http://localhost:11434", "nomic-embed-text")
result = embeddings.embed_query("test")
print(f"Embedding dimension: {len(result)}")  # Should be 768
```

4. **Test chatbot:**
```bash
python
>>> from src.agents import medical_agents
>>> response = medical_agents.handle_query("Who is Dr. Sarah Martinez?")
>>> print(response)
```

### Integration Testing

Create `tests/test_integration.py`:
```python
import pytest
from src.agents import medical_agents

def test_doctor_information_query():
    response = medical_agents.handle_query("Who is Dr. Sarah Martinez?")
    assert "Sarah Martinez" in response
    assert "Cardiology" in response or "Cardiologist" in response

def test_appointment_booking_flow():
    # Check availability
    response1 = medical_agents.handle_query(
        "Check availability for Dr. Sarah Martinez"
    )
    assert "available" in response1.lower()
    
    # Book appointment
    response2 = medical_agents.handle_query(
        "Book appointment for John Doe at 10:00 AM on 2025-12-01 with Dr. Sarah Martinez, phone 555-0000"
    )
    assert "booked" in response2.lower() or "success" in response2.lower()
```

Run tests:
```bash
pytest tests/ -v
```

---

## üö¢ Deployment

### Production Checklist

- [ ] Set `FLASK_DEBUG=False`
- [ ] Use production-grade WSGI server (Gunicorn/uWSGI)
- [ ] Set up HTTPS (SSL/TLS certificates)
- [ ] Configure firewall rules
- [ ] Set up logging and monitoring
- [ ] Implement rate limiting
- [ ] Set up database backups
- [ ] Configure error alerting
- [ ] Review and secure all API keys
- [ ] Set up load balancing (if needed)

### Deployment Options

#### Option 1: Traditional Server (Ubuntu)

```bash
# Install dependencies
sudo apt update
sudo apt install python3.8 python3-pip nginx

# Clone repository
git clone https://github.com/yourusername/medical-center-chatbot.git
cd medical-center-chatbot

# Setup virtual environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Install Gunicorn
pip install gunicorn

# Run with Gunicorn
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

**Nginx Configuration:**
```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://localhost:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

#### Option 2: Docker

**Dockerfile:**
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 5000

# Run application
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "app:app"]
```

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
    env_file:
      - .env
    restart: unless-stopped
```

Deploy:
```bash
docker-compose up -d
```

#### Option 3: Cloud Platform (Heroku)

```bash
# Login to Heroku
heroku login

# Create app
heroku create medical-chatbot

# Set environment variables
heroku config:set OPENROUTER_API_KEY=your_key
heroku config:set QDRANT_URL=your_url
# ... set all other env vars

# Deploy
git push heroku main

# Open app
heroku open
```

### Monitoring and Logging

**Setup logging:**
```python
import logging
from logging.handlers import RotatingFileHandler

if not app.debug:
    file_handler = RotatingFileHandler(
        'logs/app.log',
        maxBytes=10240000,
        backupCount=10
    )
    file_handler.setLevel(logging.INFO)
    app.logger.addHandler(file_handler)
```

**Monitor with PM2:**
```bash
npm install -g pm2
pm2 start app.py --name medical-chatbot --interpreter python3
pm2 startup
pm2 save
```

---

## üîí Security

### Security Best Practices

#### 1. Environment Variables
- **Never commit `.env` file to version control**
- Use different keys for development/production
- Rotate API keys regularly

#### 2. API Security
```python
# Rate limiting
from flask_limiter import Limiter

limiter = Limiter(
    app,
    key_func=lambda: request.remote_addr,
    default_limits=["100 per hour"]
)

@app.route('/api/chat', methods=['POST'])
@limiter.limit("10 per minute")
def chat():
    # ... existing code
```

#### 3. Input Validation
```python
from pydantic import BaseModel, validator

class ChatRequest(BaseModel):
    message: str
    
    @validator('message')
    def message_must_not_be_empty(cls, v):
        if not v.strip():
            raise ValueError('Message cannot be empty')
        if len(v) > 1000:
            raise ValueError('Message too long')
        return v
```

#### 4. HTTPS Configuration
```python
# Force HTTPS in production
@app.before_request
def before_request():
    if not request.is_secure and app.env == "production":
        url = request.url.replace("http://", "https://", 1)
        return redirect(url, code=301)
```

#### 5. CORS Configuration
```python
CORS(app, resources={
    r"/api/*": {
        "origins": ["https://your-domain.com"],
        "methods": ["GET", "POST"],
        "allow_headers": ["Content-Type"]
    }
})
```

### HIPAA Compliance Considerations

> **Note:** This is a general-purpose chatbot. For HIPAA compliance:

1. **Use local LLM processing** (Ollama only, no external APIs)
2. **Encrypt data at rest and in transit**
3. **Implement audit logging**
4. **Add user authentication**
5. **Sign Business Associate Agreements (BAAs)**
6. **Conduct regular security audits**
7. **Implement access controls**

---

## ‚ö° Performance

### Performance Metrics

| Operation | Average Time | Notes |
|-----------|--------------|-------|
| Information Query | 2-5 seconds | Includes embedding + search + LLM |
| Check Availability | 1-2 seconds | Direct Excel read |
| Book Appointment | 2-4 seconds | Excel write + validation |
| Cancel Appointment | 2-3 seconds | Excel search + write |
| Vector Search | 100-300ms | Qdrant query only |
| LLM Response | 1-3 seconds | Depends on model |

### Optimization Strategies

#### 1. Caching
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def get_doctor_info(doctor_name: str):
    """Cache doctor information"""
    return vector_manager.search(f"Dr. {doctor_name}")
```

#### 2. Connection Pooling
```python
from qdrant_client import QdrantClient

# Reuse client connections
client = QdrantClient(url=..., api_key=..., timeout=300)
```

#### 3. Batch Processing
```python
# Generate embeddings in batches
batch_size = 10
for i in range(0, len(texts), batch_size):
    batch = texts[i:i + batch_size]
    embeddings = ollama.embed_documents(batch)
```

#### 4. Response Streaming
```python
@app.route('/api/chat/stream', methods=['POST'])
def chat_stream():
    def generate():
        for chunk in get_streaming_response():
            yield f"data: {chunk}\n\n"
    
    return Response(generate(), mimetype='text/event-stream')
```

### Resource Requirements

**Development:**
- CPU: 2+ cores
- RAM: 4GB minimum
- Disk: 5GB

**Production (100 concurrent users):**
- CPU: 4+ cores
- RAM: 8GB minimum
- Disk: 20GB (with logs)
- Network: 10 Mbps

---

## üîß Troubleshooting

### Common Issues

#### Issue: "Cannot connect to Ollama"

**Symptoms:**
```
Error generating embedding: Connection refused
```

**Solution:**
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# If not running, start Ollama
ollama serve

# On Windows, Ollama should start automatically
# Check Windows Services
```

---

#### Issue: "Qdrant connection failed"

**Symptoms:**
```
Error: Failed to connect to Qdrant cluster
```

**Solution:**
1. Verify cluster URL and API key in `.env`
2. Check Qdrant cloud console for cluster status
3. Test connection:
```python
from qdrant_client import QdrantClient
client = QdrantClient(url="your_url", api_key="your_key")
print(client.get_collections())
```

---

#### Issue: "Model not found"

**Symptoms:**
```
Error: model 'nomic-embed-text' not found
```

**Solution:**
```bash
ollama pull nomic-embed-text
ollama list  # Verify installation
```

---

#### Issue: "Excel file not found"

**Symptoms:**
```
FileNotFoundError: data/Simple_Clinic_Database.xlsx
```

**Solution:**
1. Verify file exists in `data/` directory
2. Check `EXCEL_DB_PATH` in `.env`
3. Ensure correct file permissions

---

#### Issue: "Port 5000 already in use"

**Symptoms:**
```
OSError: [Errno 48] Address already in use
```

**Solution:**
```bash
# Find process using port 5000
lsof -i :5000  # macOS/Linux
netstat -ano | findstr :5000  # Windows

# Kill the process or change port in .env
FLASK_PORT=5001
```

---

#### Issue: "Slow response times"

**Solutions:**
1. Reduce `RAG_RETRIEVAL_K` to 5
2. Increase `RAG_SCORE_THRESHOLD` to 0.5
3. Use faster LLM model
4. Enable caching
5. Check network latency to Qdrant

---

### Debug Mode

Enable verbose logging:
```env
FLASK_DEBUG=True
CREW_VERBOSE=True
```

Check logs:
```python
# Add to app.py
import logging
logging.basicConfig(level=logging.DEBUG)

# In functions
app.logger.debug("Processing query: %s", user_message)
```

---

## üìÑ License

This project is licensed under the MIT License.

```
MIT License

Copyright (c) 2025 [Your Name/Organization]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ü§ù Contributing

Contributions are welcome! Please follow these guidelines:

### How to Contribute

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Commit your changes**
   ```bash
   git commit -m "Add amazing feature"
   ```
4. **Push to the branch**
   ```bash
   git push origin feature/amazing-feature
   ```
5. **Open a Pull Request**

### Contribution Guidelines

- Follow existing code style
- Add tests for new features
- Update documentation
- Keep commits focused and atomic
- Write clear commit messages

### Areas for Contribution

- üåê Multi-language support
- üì± Mobile app integration
- üìß Email/SMS notifications
- üìä Analytics dashboard
- üîí Enhanced security features
- üß™ Additional test coverage
- üìñ Documentation improvements

---

## üìû Support & Contact

### Getting Help

- **Documentation**: Read this README and QUICKSTART.md
- **Issues**: Open a GitHub issue for bugs or feature requests
- **Discussions**: Use GitHub Discussions for questions

### Useful Links

- **Ollama Documentation**: https://ollama.com/docs
- **CrewAI Documentation**: https://docs.crewai.com
- **Qdrant Documentation**: https://qdrant.tech/documentation
- **Flask Documentation**: https://flask.palletsprojects.com
- **OpenRouter Documentation**: https://openrouter.ai/docs

---

## üôè Acknowledgments

- **OpenRouter** for providing accessible LLM APIs
- **Ollama** for local AI model hosting
- **Qdrant** for powerful vector search capabilities
- **CrewAI** for multi-agent orchestration
- **Flask** for the lightweight web framework

---

## üìä Project Status

**Current Version**: 1.0.0  
**Status**: ‚úÖ Production Ready  
**Last Updated**: November 19, 2025

### Recent Updates

- ‚úÖ Initial release with full chatbot functionality
- ‚úÖ OpenRouter + Ollama hybrid architecture
- ‚úÖ Complete appointment management system
- ‚úÖ Vector database integration
- ‚úÖ Beautiful web interface

### Roadmap

- [ ] Multi-language support (Arabic, French, Spanish)
- [ ] SMS/Email appointment reminders
- [ ] Mobile app (React Native)
- [ ] Video consultation booking
- [ ] Payment integration
- [ ] Insurance verification
- [ ] Analytics dashboard
- [ ] Admin panel

---

<div align="center">

**Built with ‚ù§Ô∏è for Healthcare Providers**

[![GitHub Stars](https://img.shields.io/github/stars/yourusername/medical-center-chatbot?style=social)](https://github.com/yourusername/medical-center-chatbot)
[![Twitter Follow](https://img.shields.io/twitter/follow/yourhandle?style=social)](https://twitter.com/yourhandle)

</div>
